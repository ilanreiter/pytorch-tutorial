{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n",
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from logger import Logger\n",
    "\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MNIST dataset \n",
    "dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                     train=True, \n",
    "                                     transform=transforms.ToTensor(),  \n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet().to(device)\n",
    "\n",
    "logger = Logger('./logs')\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/10000], Loss: 1.5491, Acc: 0.80\n",
      "Step [200/10000], Loss: 1.4978, Acc: 0.74\n",
      "Step [300/10000], Loss: 1.3596, Acc: 0.80\n",
      "Step [400/10000], Loss: 1.2252, Acc: 0.85\n",
      "Step [500/10000], Loss: 1.0927, Acc: 0.84\n",
      "Step [600/10000], Loss: 1.0007, Acc: 0.94\n",
      "Step [700/10000], Loss: 1.0906, Acc: 0.83\n",
      "Step [800/10000], Loss: 1.0188, Acc: 0.85\n",
      "Step [900/10000], Loss: 0.9533, Acc: 0.87\n",
      "Step [1000/10000], Loss: 0.9583, Acc: 0.83\n",
      "Step [1100/10000], Loss: 0.8097, Acc: 0.88\n",
      "Step [1200/10000], Loss: 0.8308, Acc: 0.81\n",
      "Step [1300/10000], Loss: 0.8002, Acc: 0.81\n",
      "Step [1400/10000], Loss: 0.6830, Acc: 0.85\n",
      "Step [1500/10000], Loss: 0.6316, Acc: 0.87\n",
      "Step [1600/10000], Loss: 0.6877, Acc: 0.87\n",
      "Step [1700/10000], Loss: 0.5609, Acc: 0.89\n",
      "Step [1800/10000], Loss: 0.7048, Acc: 0.88\n",
      "Step [1900/10000], Loss: 0.6551, Acc: 0.84\n",
      "Step [2000/10000], Loss: 0.6378, Acc: 0.88\n",
      "Step [2100/10000], Loss: 0.5639, Acc: 0.86\n",
      "Step [2200/10000], Loss: 0.6056, Acc: 0.83\n",
      "Step [2300/10000], Loss: 0.5569, Acc: 0.87\n",
      "Step [2400/10000], Loss: 0.5121, Acc: 0.87\n",
      "Step [2500/10000], Loss: 0.5043, Acc: 0.88\n",
      "Step [2600/10000], Loss: 0.3866, Acc: 0.94\n",
      "Step [2700/10000], Loss: 0.5174, Acc: 0.89\n",
      "Step [2800/10000], Loss: 0.6174, Acc: 0.85\n",
      "Step [2900/10000], Loss: 0.4464, Acc: 0.88\n",
      "Step [3000/10000], Loss: 0.5007, Acc: 0.90\n",
      "Step [3100/10000], Loss: 0.5631, Acc: 0.87\n",
      "Step [3200/10000], Loss: 0.4744, Acc: 0.91\n",
      "Step [3300/10000], Loss: 0.3187, Acc: 0.92\n",
      "Step [3400/10000], Loss: 0.4094, Acc: 0.91\n",
      "Step [3500/10000], Loss: 0.3927, Acc: 0.88\n",
      "Step [3600/10000], Loss: 0.4595, Acc: 0.91\n",
      "Step [3700/10000], Loss: 0.4009, Acc: 0.89\n",
      "Step [3800/10000], Loss: 0.3586, Acc: 0.91\n",
      "Step [3900/10000], Loss: 0.4034, Acc: 0.91\n",
      "Step [4000/10000], Loss: 0.3999, Acc: 0.89\n",
      "Step [4100/10000], Loss: 0.4250, Acc: 0.90\n",
      "Step [4200/10000], Loss: 0.4225, Acc: 0.91\n",
      "Step [4300/10000], Loss: 0.4564, Acc: 0.86\n",
      "Step [4400/10000], Loss: 0.4394, Acc: 0.86\n",
      "Step [4500/10000], Loss: 0.3211, Acc: 0.92\n",
      "Step [4600/10000], Loss: 0.3616, Acc: 0.87\n",
      "Step [4700/10000], Loss: 0.4354, Acc: 0.92\n",
      "Step [4800/10000], Loss: 0.3420, Acc: 0.92\n",
      "Step [4900/10000], Loss: 0.4899, Acc: 0.86\n",
      "Step [5000/10000], Loss: 0.3659, Acc: 0.88\n",
      "Step [5100/10000], Loss: 0.3253, Acc: 0.90\n",
      "Step [5200/10000], Loss: 0.2435, Acc: 0.93\n",
      "Step [5300/10000], Loss: 0.2982, Acc: 0.90\n",
      "Step [5400/10000], Loss: 0.3044, Acc: 0.93\n",
      "Step [5500/10000], Loss: 0.3914, Acc: 0.91\n",
      "Step [5600/10000], Loss: 0.4268, Acc: 0.90\n",
      "Step [5700/10000], Loss: 0.2819, Acc: 0.91\n",
      "Step [5800/10000], Loss: 0.3875, Acc: 0.93\n",
      "Step [5900/10000], Loss: 0.2630, Acc: 0.91\n",
      "Step [6000/10000], Loss: 0.2921, Acc: 0.90\n",
      "Step [6100/10000], Loss: 0.4263, Acc: 0.88\n",
      "Step [6200/10000], Loss: 0.4212, Acc: 0.87\n",
      "Step [6300/10000], Loss: 0.2208, Acc: 0.97\n",
      "Step [6400/10000], Loss: 0.3843, Acc: 0.87\n",
      "Step [6500/10000], Loss: 0.2533, Acc: 0.95\n",
      "Step [6600/10000], Loss: 0.3850, Acc: 0.89\n",
      "Step [6700/10000], Loss: 0.2749, Acc: 0.91\n",
      "Step [6800/10000], Loss: 0.4196, Acc: 0.86\n",
      "Step [6900/10000], Loss: 0.3534, Acc: 0.87\n",
      "Step [7000/10000], Loss: 0.3729, Acc: 0.90\n",
      "Step [7100/10000], Loss: 0.2267, Acc: 0.93\n",
      "Step [7200/10000], Loss: 0.2284, Acc: 0.95\n",
      "Step [7300/10000], Loss: 0.4353, Acc: 0.89\n",
      "Step [7400/10000], Loss: 0.3563, Acc: 0.89\n",
      "Step [7500/10000], Loss: 0.2681, Acc: 0.95\n",
      "Step [7600/10000], Loss: 0.3845, Acc: 0.91\n",
      "Step [7700/10000], Loss: 0.4280, Acc: 0.88\n",
      "Step [7800/10000], Loss: 0.2359, Acc: 0.93\n",
      "Step [7900/10000], Loss: 0.2803, Acc: 0.94\n",
      "Step [8000/10000], Loss: 0.4464, Acc: 0.89\n",
      "Step [8100/10000], Loss: 0.5011, Acc: 0.87\n",
      "Step [8200/10000], Loss: 0.3394, Acc: 0.88\n",
      "Step [8300/10000], Loss: 0.5358, Acc: 0.86\n",
      "Step [8400/10000], Loss: 0.2602, Acc: 0.93\n",
      "Step [8500/10000], Loss: 0.4593, Acc: 0.90\n",
      "Step [8600/10000], Loss: 0.3336, Acc: 0.88\n",
      "Step [8700/10000], Loss: 0.2836, Acc: 0.90\n",
      "Step [8800/10000], Loss: 0.2839, Acc: 0.89\n",
      "Step [8900/10000], Loss: 0.2145, Acc: 0.96\n",
      "Step [9000/10000], Loss: 0.3784, Acc: 0.89\n",
      "Step [9100/10000], Loss: 0.3357, Acc: 0.88\n",
      "Step [9200/10000], Loss: 0.3558, Acc: 0.89\n",
      "Step [9300/10000], Loss: 0.3271, Acc: 0.93\n",
      "Step [9400/10000], Loss: 0.1941, Acc: 0.95\n",
      "Step [9500/10000], Loss: 0.3537, Acc: 0.89\n",
      "Step [9600/10000], Loss: 0.2614, Acc: 0.92\n",
      "Step [9700/10000], Loss: 0.2880, Acc: 0.91\n",
      "Step [9800/10000], Loss: 0.3642, Acc: 0.89\n",
      "Step [9900/10000], Loss: 0.1772, Acc: 0.97\n",
      "Step [10000/10000], Loss: 0.1993, Acc: 0.94\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 10000\n",
    "\n",
    "# Start training\n",
    "for step in range(total_step):\n",
    "    \n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch images and labels\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute accuracy\n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
    "               .format(step+1, total_step, loss.item(), accuracy.item()))\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                        Tensorboard Logging                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 1. Log scalar values (scalar summary)\n",
    "        info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step+1)\n",
    "\n",
    "        # 2. Log values and gradients of the parameters (histogram summary)\n",
    "        for tag, value in model.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            logger.histo_summary(tag, value.data.cpu().numpy(), step+1)\n",
    "            logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
    "\n",
    "        # 3. Log training images (image summary)\n",
    "        info = { 'images': images.view(-1, 28, 28)[:10].cpu().numpy() }\n",
    "\n",
    "        for tag, images in info.items():\n",
    "            logger.image_summary(tag, images, step+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results go into even.out.tfeventfiles withing the logs folder uner the current folder. \n",
    "To run the tensorbpard the command is: \n",
    "\n",
    "$  cd .\\OneDrive\\Python\\PyTorch\\pytorch-tutorial\\tutorials\\04-utils\\tensorboard\\\n",
    "$ ``tensorboard --logdir .\\logs --host localhost''\n",
    "\n",
    "To see the tensorboard in the browser: ``tp://localhost:6006``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
